---
title: "Why are my pipeline download tests failing?"
subtitle: "Refurbishing the pipeline downloads command"
headerImage: "https://images.unsplash.com/photo-1636819488537-a9b1ffb315ce"
headerImageAlt: "3D rendering of a cute little space rocket painted red and white with a fluffy smoke cloud coming out of it."
pubDate: 2025-08-15T12:00:00+01:00
authors:
    - "ErikDanielsson"
label:
    - "tools"
maxHeadingDepth: 3
---

import { Image } from "astro:assets";

import old_nf_version from "@assets/images/blog/pipeline-download-refactor/old-nf-version.png";
import rnaseq_in_action from "@assets/images/blog/pipeline-download-refactor/rnaseq-in-action.png";

The `nf-core pipelines download` command, used when you want to run an `nf-core` pipeline in an offline compute environment, has recently undergone a [substantial refactor](https://github.com/nf-core/tools/pull/3634) that has recently been merged into the development version of `nf-core/tools`.
The command has for a long time been reliant on complex regex logic to capture container strings in modules and config files.
Due to the variability in where a pipeline can define containers, this has been prone to breaking.

Not anymore!
As of [Nextflow 25.04](https://www.nextflow.io/docs/latest/migrations/25-04.html) the `nextflow inspect` command has been substantially extended to allow fetching of all pipeline containers by executing a dry-run of the pipeline.
This has now been integrated into the `nf-core/tools` code base which means that the download command can offload the tricky problem of finding pipeline containers to Nextflow, making the command simpler and more reliant at the same time.

:::warning{title="Why are is the pipeline download tests failing?!"}

<Image
    src={old_nf_version}
    class="d-block m-auto"
    width={600}
    density={[1.5, 2]}
    alt="Using an old Nextflow version"
    height="300"
/>

Each `nf-core` pipeline repository has a GitHub workflow that runs the `nf-core pipelines download` command on the pipeline (see for example the [`nf-core/rnaseq` workflow](https://github.com/nf-core/rnaseq/actions/workflows/download_pipeline.yml)).
This workflow checks that the pipeline does not produce any errors when downloaded, to ensure that the pipeline can be used in an offline enviroment.
The workflow is typically only triggered when a PR is made to the pipeline's main branch, i.e. only on release of the pipeline.

The GitHub workflow currently uses the **`dev`** branch of `nf-core/tools`; originally to allow maintainers of `nf-core/tools` to quickly push patches when the regex logic broke.
However, this means that _any_ changes made to the development version of `nf-core/tools` will directly take effect in the GitHub workflow.
Since the refactor of the downloads code requires that the pipeline uses the **25.04** version of Nextflow, pipelines that do not comply with this will fail the download test.

In time, there will be a pipeline template update that will require pipelines to use Nextflow `>=` 25.04, and to thus be compatible with the new command.
The test itself will also be updated to use the `main` branch of `nf-core/tools` to avoid similar issues in the future.
Until then, you can either voluntarily update the pipelines Nextflow version or ignore the failing test.

:::

### Added support for downloading Docker containers

<Image
    src={rnaseq_in_action}
    class="d-block m-auto"
    width={600}
    density={[1.5, 2]}
    alt="Docker container download for `rnaseq` 3.19.0"
/>

In addition to the use of `nextflow inspect` for container detection, the download command now also support downloads of Docker container images.
This means that `nf-core` pipelines can now be run on offline HPCs which support only Docker or Podman container systems.

:::tip{title="How are Docker images saved?"}

Compared to Singularity containers which are files kept on your file system, Docker images are generally handled by the Docker daemon.
However, via the [`docker image save`](https://docs.docker.com/reference/cli/docker/image/save/) command, Docker allows packaging images as `tar` archives.
The `tar` archives can subsequently be loaded into another Docker daemon with [`docker image load`](https://docs.docker.com/reference/cli/docker/image/load/), or if you are running Podman with [`podman load`](https://docs.podman.io/en/v5.0.2/markdown/podman-load.1.html).

The `nf-core pipelines downloads` command creates `tar` archives for each Docker image within the pipeline.
The saved archives are then packaged along with scripts for loading them into Docker or Podman on the offline machine.
Along with the Docker images are scripts for loading the `tar` archives into the Docker or Podman daemon on the offline machine.

:::

### Further details

More details on the changes can be found in the corresponding PRs on `nf-core/tools`(
[#3634](https://github.com/nf-core/tools/pull/3634),
[#3706](https://github.com/nf-core/tools/pull/3706),
[#3696](https://github.com/nf-core/tools/pull/3696)
)

If you find any bugs to the download command after the recent major changes, please tell us on the [#tools](https://nfcore.slack.com/archives/CE5LG7WMB) Slack channel or create an issue on [nf-core/tools](https://github.com/nf-core/tools/) detailing the problem.
